{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Разработка модели детекции наклеек: Faster R-CNN"
      ],
      "metadata": {
        "id": "5WizLuz_Tu7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfUG3EKbRqK2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка предобученной модели Faster R-CNN"
      ],
      "metadata": {
        "id": "a5EW7fmvSE9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
      ],
      "metadata": {
        "id": "YWpfYLeHSFIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пользовательский классификатор"
      ],
      "metadata": {
        "id": "C7hWcmnLSN_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2  # фон и наклейка\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ],
      "metadata": {
        "id": "S_pI9uS8SOPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "JyY-_d_QSkCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, annotations, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
        "        self.annotations = list(sorted(os.listdir(os.path.join(root, \"annotations\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Загрузка изображений и аннотаций\n",
        "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "        ann_path = os.path.join(self.root, \"annotations\", self.annotations[idx])\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Загрузка файла аннотации\n",
        "        with open(ann_path) as f:\n",
        "            boxes = json.load(f)[\"boxes\"]\n",
        "\n",
        "        # Конвертация координат боксов в тензор Torch\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "        num_objs = len(boxes)\n",
        "        # Пометка класса наклейки как 1 (предполагая, что 0 - это фон)\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "63UzH0wpSkMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        # Дополнительные трансформации для обучения\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "LlWEbDoFS0vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение модели"
      ],
      "metadata": {
        "id": "gH3yNywRSl-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "\n",
        "def train_model(model, data_loader, optimizer, device, num_epochs=3):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # оценка на каждом шаге\n",
        "        evaluate(model, data_loader, device=device)\n"
      ],
      "metadata": {
        "id": "4TxxTly0SmM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Инициализация датасета, DataLoader и модели\n",
        "dataset = CustomDataset(root=\"path/to/images\", annotations=\"path/to/annotations\", transforms=get_transform(train=True))\n",
        "\n",
        "# Определение размеров выборок\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Разделение датасета на обучающую и тестовую выборки\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Инициализация оптимизатора\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# Запуск обучения\n",
        "train_model(model, train_loader, optimizer, device)\n"
      ],
      "metadata": {
        "id": "BkhylHLhTIUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сохранение модели"
      ],
      "metadata": {
        "id": "t3cqJD0HR5UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')"
      ],
      "metadata": {
        "id": "Bvc_e5xiR5uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель распознавания текста с наклеек: Tesseract OCR\n",
        " Является одним из наиболее широко используемых инструментов OCR, поддерживает множество языков и имеет хорошую точность распознавания текста."
      ],
      "metadata": {
        "id": "ci7KXyN7tZRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytesseract\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKSFW14UtgAY",
        "outputId": "4135635f-978d-4675-a3c0-dc78d7f13ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# Функция для извлечения текста из области изображения\n",
        "def extract_text_from_image(image, box):\n",
        "    # Обрезка изображения по указанной области\n",
        "    cropped_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "    # Распознавание текста с помощью Tesseract OCR\n",
        "    text = pytesseract.image_to_string(cropped_image, lang='eng')\n",
        "    return text"
      ],
      "metadata": {
        "id": "n_yKRXu8tifw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Извлечение текста из изображений исходя из полученной ранее разметки"
      ],
      "metadata": {
        "id": "VfyKMMGYuPYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка обученной модели\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2)\n",
        "model.load_state_dict(torch.load('fasterrcnn_resnet50_fpn.pth'))\n",
        "\n",
        "# Перевод модели в режим оценки\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "y5jHJwSrvCM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import functional as F\n",
        "\n",
        "def prepare_image(image_path):\n",
        "    # Загрузка изображения\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert(\"RGB\")\n",
        "    # Преобразование изображения в тензор\n",
        "    image = F.to_tensor(image)\n",
        "    return image"
      ],
      "metadata": {
        "id": "TxajbbzNvIEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()  # Отключение расчета градиентов\n",
        "def get_predictions(model, data_loader):\n",
        "    model.eval()  # Перевод модели в режим оценки\n",
        "    predictions = []\n",
        "    for images, _ in data_loader:\n",
        "        images = [image.to(device) for image in images]\n",
        "        outputs = model(images)\n",
        "        predictions.extend(outputs)\n",
        "    return predictions\n",
        "\n",
        "# Получение предсказаний, используя test_loader\n",
        "predictions = get_predictions(model, test_loader)\n"
      ],
      "metadata": {
        "id": "Ou0JbFVXvM0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечение текста из каждой области\n",
        "texts = [extract_text_from_image(img, target) for img, target in predictions]"
      ],
      "metadata": {
        "id": "_boeXoVRtsc_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}